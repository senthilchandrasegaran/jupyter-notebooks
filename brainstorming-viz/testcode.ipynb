{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import codecs\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'codecs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e6d0dedef2aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Open and read transcripts in NLTK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../../private/brainstorming_viz_data/free_group/teamA_part1_divergent.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../../private/brainstorming_viz_data/free_group/teamA_part2_convergent.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf1Temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tempASCII'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf2Temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tempASCII'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'codecs' is not defined"
     ]
    }
   ],
   "source": [
    "# Open and read transcripts in NLTK\n",
    "f1=codecs.open('../../../private/brainstorming_viz_data/free_group/teamA_part1_divergent.txt', 'r', encoding='utf-8')\n",
    "f2=codecs.open('../../../private/brainstorming_viz_data/free_group/teamA_part2_convergent.txt', 'r', encoding='utf-8')\n",
    "f1Temp = codecs.open('tempASCII', 'w', encoding='ascii', errors='ignore')\n",
    "f2Temp = codecs.open('tempASCII', 'w', encoding='ascii', errors='ignore')\n",
    "f1Temp.write('free_group/teamA_part1_divergent_bak.txt')\n",
    "f2Temp.write('free_group/teamA_part1_convergent_bak.txt')\n",
    "divergent_raw = f1.read()\n",
    "convergent_raw = f2.read()\n",
    "regex = re.compile(\".*?\\[(.*?)\\]\")\n",
    "\n",
    "\n",
    "def removeObservations(test_str):\n",
    "    # removes all text within parantheses\n",
    "    # these are usually observations by the transcriber\n",
    "    # and thus should not be considered in content analysis\n",
    "    # code from http://stackoverflow.com/questions/14596884/remove-text-between-and-in-python\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret\n",
    "\n",
    "divergent = removeObservations(divergent_raw)\n",
    "convergent = removeObservations(convergent_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5152bdace452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract Noun phrases using TextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mblobDivergent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdivergent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mblobConvergent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvergent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnounDiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblobDivergent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnounConv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblobConvergent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract Noun phrases using TextBlob\n",
    "blobDivergent = TextBlob(divergent)\n",
    "blobConvergent = TextBlob(convergent)\n",
    "nounDiv = blobDivergent.np_counts\n",
    "nounConv = blobConvergent.np_counts\n",
    "dfnp1 = pd.DataFrame(columns=['Noun phrases in Divergent phase', 'Frequencies'])\n",
    "dfnp2 = pd.DataFrame(columns=['Noun phrases in Convergent phase', 'Frequencies'])\n",
    "u=1\n",
    "for i in nounDiv:\n",
    "    dfnp1.loc[u] = [i, nounDiv[i]]\n",
    "    u+=1\n",
    "\n",
    "u=1\n",
    "for i in nounConv:\n",
    "    dfnp2.loc[u] = [i, nounConv[i]]\n",
    "    u+=1\n",
    "    \n",
    "print(\"The total number of noun phrases in the divergent phase:\", len(nounDiv))\n",
    "dfnp1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nounConv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4c5e2e084fb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The total number of noun phrases in the convergent phase:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnounConv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdfnp2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nounConv' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"The total number of noun phrases in the convergent phase:\", len(nounConv))\n",
    "dfnp2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7ff90581c364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnotcommon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Common noun phrases\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Divergent\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Convergent\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnounDiv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Common noun phrases in both phases\n",
    "common = {}\n",
    "notcommon = {}\n",
    "dfc = pd.DataFrame(columns=[\"Common noun phrases\", \"Divergent\", \"Convergent\"])\n",
    "u=1\n",
    "for i in nounDiv:\n",
    "    if i in nounConv:\n",
    "        common[i] = min(nounDiv[i], nounConv[i])\n",
    "        notcommon[i] = (nounDiv[i], nounConv[i])\n",
    "        dfc.loc[u] = [i, nounDiv[i], nounConv[i]]\n",
    "        u+=1\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Noun phrases that can be removed:\n",
    "to_be_removed = [u'okay', u'yeah']\n",
    "keys_to_delete = []\n",
    "for key in common.keys():\n",
    "    if key in to_be_removed:\n",
    "        keys_to_delete.append(key)\n",
    "for key in keys_to_delete:\n",
    "    del common[key] # could not have deleted item from iterable \n",
    "                    # from within the loop\n",
    "ccommon=common.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to count co-occurrences of common noun phrases in sentences\n",
    "def occurrences(source, terms):\n",
    "    ALL_sentences=sent_tokenize(source) # creates a list of sentences\n",
    "    combinations_terms = list(itertools.combinations(terms,2)) # NC2 of terms\n",
    "    n = len(combinations_terms)\n",
    "    occurlist = []\n",
    "    for i in range(1, n):\n",
    "        for j in ALL_sentences:\n",
    "            temp = list(combinations_terms[i])\n",
    "            # Find every combination of term 1 followed by term 2 in\n",
    "            # term pair (1,2)\n",
    "            out=re.compile(str(temp[0]) + '(.*?)' + str(temp[1]), \n",
    "                           re.DOTALL | re.IGNORECASE).findall(j)\n",
    "            if out:\n",
    "                occurlist.append(str(temp[0]) + ' - ' + str(temp[1]))\n",
    "            # Find every combination of term 2 followed by term 1 in\n",
    "            # term pair (1,2)\n",
    "            out2 = re.compile(str(temp[1]) + '(.*?)' + str(temp[0]),\n",
    "                             re.DOTALL | re.IGNORECASE).findall(j)\n",
    "            if out2:\n",
    "                occurlist.append(str(temp[1]) + ' - ' + str(temp[0]))\n",
    "    occurdict = {}\n",
    "    # count occurrences of term pairs\n",
    "    for i in occurlist:\n",
    "        if i not in occurdict:\n",
    "            occurdict[i] = 1\n",
    "        else : \n",
    "            occurdict[i] = occurdict[i] + 1\n",
    "    return occurdict\n",
    "\n",
    "# Call function to find divergent and convergent terms\n",
    "Divdict = occurrences(divergent, ccommon)\n",
    "Convdict = occurrences(convergent, ccommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Divdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1b7d484ef808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mGDiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakegraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDivdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mGConv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakegraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConvdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Divdict' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to construct a graph of common noun phrases tied by \n",
    "# their co-occurrences in sentences of a transcript\n",
    "def makegraph(occurrences):\n",
    "    G = nx.Graph()\n",
    "    for edgs,wt in occurrences.items():\n",
    "        edg = edgs.split(' - ')\n",
    "        G.add_edge(edg[0], edg[1], weight=wt)\n",
    "        G.add_node(edg[0], label = edg[0])\n",
    "        G.add_node(edg[1], label=edg[1])\n",
    "    return G\n",
    "\n",
    "GDiv = makegraph(Divdict)\n",
    "GConv = makegraph(Convdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5ea281158b36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot graph of common phrases in Team A's divergent phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphviz_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGDiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msstt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Team A's wordnet during divergent phase of brainstorming\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m possit = nx.draw_networkx(GDiv, sstt, pos=pos, with_edgewidth=True, withLabels=True,\n\u001b[0;32m      5\u001b[0m                       labfs=15, valpha=0.2, ealpha=0.7, labelfont=15)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nx' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot graph of common phrases in Team A's divergent phase\n",
    "pos = nx.graphviz_layout(GDiv, prog=\"dot\")\n",
    "sstt=\"Team A's wordnet during divergent phase of brainstorming\"\n",
    "possit = nx.draw_networkx(GDiv, sstt, pos=pos, with_edgewidth=True, withLabels=True,\n",
    "                      labfs=15, valpha=0.2, ealpha=0.7, labelfont=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
